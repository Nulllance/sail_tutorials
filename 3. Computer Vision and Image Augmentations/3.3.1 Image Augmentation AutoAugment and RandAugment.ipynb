{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3.1 Image Augmentation: AutoAugment and RandAugment\n",
    "By Zac Todd\n",
    "\n",
    "This tutorials covers image augmenations included in the Cubuk et al works [AutoAugement](https://arxiv.org/abs/1805.09501) and [RandAugment](https://arxiv.org/abs/1909.13719). It will cover operations such as shear,\n",
    "translate, rotate, auto contrast, invert, equalize, solarize, posterize, contrast, color, brightness, and sharpness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "IMAGES_DIR = f'{os.getcwd()}/resources'\n",
    "IMAGE_1 = f'{IMAGES_DIR}/cat_on_dog.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformtions\n",
    "Affine transformation can be performed using PIL.Image transofmration, we will go over the shear, translateion and rotation transformations.\n",
    "### Shear\n",
    "We can apply the shear with the following matrix.\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "tex2jax: {\n",
    "inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "processEscapes: true},\n",
    "jax: [\"input/TeX\",\"input/MathML\",\"input/AsciiMath\",\"output/CommonHTML\"],\n",
    "extensions: [\"tex2jax.js\",\"mml2jax.js\",\"asciimath2jax.js\",\"MathMenu.js\",\"MathZoom.js\",\"AssistiveMML.js\", \"[Contrib]/a11y/accessibility-menu.js\"],\n",
    "TeX: {\n",
    "extensions: [\"AMSmath.js\",\"AMSsymbols.js\",\"noErrors.js\",\"noUndefined.js\"],\n",
    "equationNumbers: {\n",
    "autoNumber: \"AMS\"\n",
    "}\n",
    "}\n",
    "});\n",
    "</script>\n",
    "\n",
    "$$\n",
    "S(x, y) = \\begin{bmatrix}\n",
    "1 & y & 0\\\\\n",
    "x & 1 & 0\\\\\n",
    "0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We will start with by implmenting a hozizontal shear $S(x, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shear_x(image, sx):\n",
    "    transform = (1, 0, 0,\n",
    "                 sx, 1, 0,\n",
    "                 0, 0, 1)\n",
    "    output = image.transform(img.size, Image.AFFINE, transform)\n",
    "    return output\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "shear_x_img = shear_x(img, 0.1)\n",
    "shear_x_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "tex2jax: {\n",
    "inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "processEscapes: true},\n",
    "jax: [\"input/TeX\",\"input/MathML\",\"input/AsciiMath\",\"output/CommonHTML\"],\n",
    "extensions: [\"tex2jax.js\",\"mml2jax.js\",\"asciimath2jax.js\",\"MathMenu.js\",\"MathZoom.js\",\"AssistiveMML.js\", \"[Contrib]/a11y/accessibility-menu.js\"],\n",
    "TeX: {\n",
    "extensions: [\"AMSmath.js\",\"AMSsymbols.js\",\"noErrors.js\",\"noUndefined.js\"],\n",
    "equationNumbers: {\n",
    "autoNumber: \"AMS\"\n",
    "}\n",
    "}\n",
    "});\n",
    "</script>\n",
    "Now you can implment shearing in the vectical direction direction using $S(0, y)$, by implmeneting *shear_y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shear_y(image, sy):\n",
    "    transform = ...\n",
    "    output = image.transform(img.size, Image.AFFINE, transform)\n",
    "    return output\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "shear_x_img = shear_y(img, 0.1)\n",
    "shear_y_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate\n",
    "Translation allows us to shift images in th horizontal and vectical direction using the following matrix.\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "tex2jax: {\n",
    "inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "processEscapes: true},\n",
    "jax: [\"input/TeX\",\"input/MathML\",\"input/AsciiMath\",\"output/CommonHTML\"],\n",
    "extensions: [\"tex2jax.js\",\"mml2jax.js\",\"asciimath2jax.js\",\"MathMenu.js\",\"MathZoom.js\",\"AssistiveMML.js\", \"[Contrib]/a11y/accessibility-menu.js\"],\n",
    "TeX: {\n",
    "extensions: [\"AMSmath.js\",\"AMSsymbols.js\",\"noErrors.js\",\"noUndefined.js\"],\n",
    "equationNumbers: {\n",
    "autoNumber: \"AMS\"\n",
    "}\n",
    "}\n",
    "});\n",
    "</script>\n",
    "\n",
    "$$\n",
    "T(x, y) = \\begin{bmatrix}\n",
    "1 & 0 & x\\\\\n",
    "0 & 1 & y\\\\\n",
    "0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Use this matrix to write two function; *translate_x* for horizontal translation and *translate_y* for vectical translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_x(image, tx) -> np.ndarray:\n",
    "    transform = ...\n",
    "    output = image.transform(img.size, Image.AFFINE, transform)\n",
    "    return output\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "translate_x_img = translate_x(img, 0.5)\n",
    "translate_x_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_y(image, ty):\n",
    "    transform = ...\n",
    "    output = image.transform(img.size, Image.AFFINE, transform)\n",
    "    return output\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "translate_y_img = translate_y(img, 100)\n",
    "translate_y_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate\n",
    "The affine matrix for rotation is the following.\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "tex2jax: {\n",
    "inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "processEscapes: true},\n",
    "jax: [\"input/TeX\",\"input/MathML\",\"input/AsciiMath\",\"output/CommonHTML\"],\n",
    "extensions: [\"tex2jax.js\",\"mml2jax.js\",\"asciimath2jax.js\",\"MathMenu.js\",\"MathZoom.js\",\"AssistiveMML.js\", \"[Contrib]/a11y/accessibility-menu.js\"],\n",
    "TeX: {\n",
    "extensions: [\"AMSmath.js\",\"AMSsymbols.js\",\"noErrors.js\",\"noUndefined.js\"],\n",
    "equationNumbers: {\n",
    "autoNumber: \"AMS\"\n",
    "}\n",
    "}\n",
    "});\n",
    "</script>\n",
    "$$\n",
    "R(\\theta) = \\begin{bmatrix}\n",
    "cos(\\theta) & sin(\\theta) & 0\\\\\n",
    "-sin(\\theta) & cos(\\theta) & 0\\\\\n",
    "0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To peform a rotation around a point you have to tranlate it, rotate and translate it back.\n",
    "\n",
    "\n",
    "$$ T(x, y) \\cdot R(\\theta) \\cdot T(-x, -y) $$\n",
    "\n",
    "\n",
    "Apply this by tranformin an image by rotating it around it centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(image, theta):\n",
    "    w, h = image.size\n",
    "    tx, ty = ...\n",
    "    transform = ...\n",
    "    output = image.transform(img.size, Image.AFFINE, transform)\n",
    "    return output\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "rotate_img = rotate(img, np.radians(30))\n",
    "rotate_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotations can also be performed with .rotate(.) on PIL Image objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Enhancement\n",
    "We will look at image enhancements opertions using PIL.ImageOps and PIL.ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageEnhance\n",
    "In ImageEnhance the classes of intrest are *Color*, *Contrast*, *Brightness* and *Shrapen* and can be by changing the following:\n",
    "```python\n",
    "ImageEnhance.Enhancement(image).enhance(factor)\n",
    "```\n",
    "\n",
    "Play around with these enhancement in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(IMAGE_1)\n",
    "enhanced_img = ImageEnhance. ...\n",
    "enhanced_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageOps\n",
    "The reamining Enhancements uses the ImageOp with the ImageOps function autocontrast, invert, equalise, solarize, and posterize.\n",
    "play around with e function and determine the other required inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(IMAGE_1)\n",
    "enhanced_img = ImageOps. ...\n",
    "enhanced_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoAugment\n",
    "We will now implement auto augment polices, though in prataisit the input are optimised for the dataset will will just uses the the ImageNet implmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (prob, name, magtitude)\n",
    "IMAGENET_POLICIES = [\n",
    "    ((0.4, 'Posterize', 8), (0.6, 'Rotate', 9)),\n",
    "    ((0.8, 'Solarize', 5), (0.6, 'Autocontrast', 5)),\n",
    "    ((0.6, 'Equalize', 8), (0.6, 'Equalize', 3)),\n",
    "    ((0.6, 'Posterize', 7), (0.6, 'Posterize', 7)),\n",
    "    ((0.2, \"Rotate\", 3), (0.6, \"Solarize\", 8)),\n",
    "    ((0.6, \"Equalize\", 8), (0.4, \"Posterize\", 6)),\n",
    "    ((0.8, \"Rotate\", 8), (0.4, \"Color\", 0)),\n",
    "    ((0.4, \"Rotate\", 9), (0.6, \"Equalize\", 2)),\n",
    "    ((0.0, \"Equalize\", 7), (0.8, \"Equalize\", 8)),\n",
    "    ((0.6, \"Invert\", 4), (0.6, \"Equalize\", 8)),\n",
    "    ((0.6, \"Color\", 4), (0.8, \"Contrast\", 8)),\n",
    "    ((0.8, \"Rotate\", 8), (0.4, \"Color\", 2)),\n",
    "    ((0.8, \"Color\", 8), (0.8, \"Solarize\", 7)),\n",
    "    ((0.4, \"Sharpness\", 7), (0.6, \"Invert\", 8)),\n",
    "    ((0.6, \"ShearX\", 5), (0.4, \"Equalize\", 9)),\n",
    "    ((0.4, \"Color\", 0), (0.6, \"Equalize\", 3)),\n",
    "    ((0.4, \"Equalize\", 7), (0.2, \"Solarize\", 4)),\n",
    "    ((0.6, \"Solarize\", 5), (0.6, \"Autocontrast\", 5)),\n",
    "    ((0.6, \"Invert\", 4), (0.6, \"Equalize\", 8)),\n",
    "    ((0.6, \"Color\", 4), (0.8, \"Contrast\", 8)),\n",
    "    ((0.8, \"Equalize\", 8), (0.6, \"Equalize\", 3))\n",
    "]\n",
    "IMAGENET_POLICIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoAugment determines it transformation the input magitude using the *RANGES* dict where the magitude of each augmenation represent the index of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGES = {\n",
    "    'ShearX': np.linspace(0, 0.3, 10),\n",
    "    'ShearY': np.linspace(0, 0.3, 10),\n",
    "    'TranslateX': np.linspace(0, 150 / 331, 10),\n",
    "    'TranslateY': np.linspace(0, 150 / 331, 10),\n",
    "    'Rotate': np.linspace(0, 30, 10),\n",
    "    'Color': np.linspace(0.0, 0.9, 10),\n",
    "    'Posterize': np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
    "    'Solarize': np.linspace(256, 0, 10),\n",
    "    'Contrast': np.linspace(0.0, 0.9, 10),\n",
    "    'Sharpness': np.linspace(0.0, 0.9, 10),\n",
    "    'Brightness': np.linspace(0.0, 0.9, 10),\n",
    "    'AutoContrast': [0] * 10,\n",
    "    'Equalize': [0] * 10,\n",
    "    'Invert': [0] * 10\n",
    "}\n",
    "RANGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *AUTOAUGMENT_TRANSFORMATIONS* dictionary contains the function calls we need to make to perform the transformations, it takes the affine tranformation you implmented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(m):\n",
    "    return 1 + m * random.choice([1, -1])\n",
    "\n",
    "AUTOAUGMENT_TRANSFORMATIONS = {\n",
    "    'Invert': lambda img, _: img,\n",
    "    'AutoContrast': lambda img, _: ImageOps.autocontrast(img),\n",
    "    'Equalize': lambda img, m: ImageOps.equalize(img, m),\n",
    "    'Rotate': rotate,\n",
    "    'Solarize': lambda img, m: ImageOps.solarize(img, m),\n",
    "    'Color': lambda img, m: ImageEnhance.Color(img).enhance(enhance(m)),\n",
    "    'Posterize': lambda img, m: ImageOps.posterize(img, m),\n",
    "    'Contrast': lambda img, m:  ImageEnhance.Contrast(img).enhance(enhance(m)),\n",
    "    'Brightness': lambda img, m: ImageEnhance.Brightness(img).enhance(enhance(m)),\n",
    "    'Sharpness': lambda img, m: ImageEnhance.Sharpness(img).enhance(enhance(m)),\n",
    "    'ShearX': shear_x,\n",
    "    'ShearY': shear_y,\n",
    "    'TranslateX': translate_x,\n",
    "    'TranslateY': translate_y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "policies=IMAGENET_POLICIES\n",
    "policies\n",
    "random.choice(policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly we will apply autoaugment to an image using the auto_augment(.) and apply_auto_augment(.), run a few times to see different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_augment(policies):\n",
    "    ((p1, a1, m1), (p2, a2, m2)) = random.choice(policies)\n",
    "    augmentations = []\n",
    "    if np.random.random() < p1:\n",
    "        augmentations.append((a1, m1))\n",
    "    if np.random.random() < p2:\n",
    "        augmentations.append((a2, m2))\n",
    "    return augmentations\n",
    "\n",
    "def apply_auto_augment(image, augmenations):\n",
    "    output = image.copy()\n",
    "    for a, m in augmenations:\n",
    "        output = AUTOAUGMENT_TRANSFORMATIONS[a](output, RANGES[a][m])\n",
    "    return output\n",
    "\n",
    "print('AutoAugment')\n",
    "augments = auto_augment(IMAGENET_POLICIES)\n",
    "print('Augmenations: \\n\\t ->' + '\\n\\t ->'.join(f'{a} with M={m}' for a, m in augments))\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "img_augemnt = apply_auto_augment(img, augments)\n",
    "img_augemnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandAugment\n",
    "An alterntive to AutoAugment is RandAugment instead of applying policies RandAugment applies N transformation in sequnces using "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandAugment uses an input M to set the magitude of the transformation the *LEVELS* dictionary contains the transformation to M to enable to be inputed into our transformation functions.\n",
    "Where our transformation do not take M we return the magitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_solarize(magitude):\n",
    "    return int(2.56 * magitude)\n",
    "\n",
    "def level_shear(magitude):\n",
    "    return 0.03 * magitude\n",
    "\n",
    "def level_translate(magitude):\n",
    "    return  0.045 * magitude\n",
    "\n",
    "def level_enhance(magitude):\n",
    "    return magitude * 0.18 + 0.1\n",
    "\n",
    "def level_posterize(magitude):\n",
    "    return int(0.4 * magitude)\n",
    "\n",
    "def level_rotate(magitude):\n",
    "    return np.radians(3 * magitude)\n",
    "\n",
    "LEVEL = {\n",
    "    'Identity': lambda m: m,\n",
    "    'AutoContrast': lambda m: m,\n",
    "    'Invert': lambda m: m,\n",
    "    'Equalize': lambda m: m,\n",
    "    'Rotate': level_rotate,\n",
    "    'Solarize': level_solarize,\n",
    "    'Color': level_enhance,\n",
    "    'Posterize': level_posterize,\n",
    "    'Contrast': level_enhance,\n",
    "    'Brightness': level_enhance,\n",
    "    'Sharpness': level_enhance,\n",
    "    'ShearX': level_shear,\n",
    "    'ShearY': level_shear,\n",
    "    'TranslateX': level_translate,\n",
    "    'TranslateY': level_translate\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *RANDAUGMENT_TRANSFORMATIONS* dictionary contains the function calls we need to make to perform the transformations, it takes the affine tranformation you implmented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDAUGMENT_TRANSFORMATIONS = {\n",
    "    'Identity': lambda img, _: img,\n",
    "    'AutoContrast': lambda img, _: ImageOps.autocontrast(img),\n",
    "    'Equalize': lambda img, lvl: ImageOps.equalize(img, lvl),\n",
    "    'Rotate': rotate,\n",
    "    'Solarize': lambda img, lvl: ImageOps.solarize(img, lvl),\n",
    "    'Color': lambda img, lvl: ImageEnhance.Color(img).enhance(lvl),\n",
    "    'Posterize': lambda img, lvl: ImageOps.posterize(img, lvl),\n",
    "    'Contrast': lambda img, lvl:  ImageEnhance.Contrast(img).enhance(lvl),\n",
    "    'Brightness': lambda img, lvl: ImageEnhance.Brightness(img).enhance(lvl),\n",
    "    'Sharpness': lambda img, lvl: ImageEnhance.Sharpness(img).enhance(lvl),\n",
    "    'ShearX': shear_x,\n",
    "    'ShearY': shear_y,\n",
    "    'TranslateX': translate_x,\n",
    "    'TranslateY': translate_y\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly we will apply randaugment to an image using the *randaugment(.)* and *apply_augment(.)*, play around with *N* and *M* to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randaugment(n):\n",
    "    sampled_ops = np.random.choice(list(RANDAUGMENT_TRANSFORMATIONS.keys()), n)\n",
    "    return [op for op in sampled_ops]\n",
    "\n",
    "\n",
    "def apply_randaugment(image, augmenations, magitude):\n",
    "    output = image.copy()\n",
    "    for op in augmenations:\n",
    "        lvl = LEVEL[op](magitude)\n",
    "        output = RANDAUGMENT_TRANSFORMATIONS[op](output, lvl)\n",
    "    return output\n",
    "\n",
    "N = 2\n",
    "M = 5\n",
    "\n",
    "print(f'RandAugment with N={N}, M={M}')\n",
    "augments = randaugment(N)\n",
    "print('Augmenations: \\n\\t ->' + '\\n\\t ->'.join(augments))\n",
    "\n",
    "img = Image.open(IMAGE_1)\n",
    "img_randaugemnt = apply_randaugment(img, augments, M)\n",
    "img_randaugemnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
